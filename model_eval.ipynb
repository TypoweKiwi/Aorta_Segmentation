{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b1dd9",
   "metadata": {
    "id": "866b1dd9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch as tc\n",
    "import json\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from monai.networks.nets import UNet\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Aorta_Segmentation')\n",
    "from Dataset_loader import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_path(path):\n",
    "    info_dict = tc.load(path)\n",
    "    train_loss_lst = info_dict[\"train_loss_lst\"]\n",
    "    val_loss_lst = info_dict[\"val_loss_lst\"]\n",
    "    time = info_dict[\"time\"]\n",
    "    return train_loss_lst, val_loss_lst, time\n",
    "\n",
    "Unet_train_losses, Unet_val_losses, Unet_time = get_info_from_path('/content/drive/MyDrive/Aorta_Segmentation/Training_info/UNet_losses.pt')\n",
    "FCN_train_losses, FCN_val_losses, FCN_time = get_info_from_path('/content/drive/MyDrive/Aorta_Segmentation/Training_info/FCN_losses.pt')\n",
    "FCN_pretrained_train_losses, FCN_pretrained_val_losses, FCN_pretrained_time = get_info_from_path('/content/drive/MyDrive/Aorta_Segmentation/Training_info/FCN_pretrained_losses.pt')\n",
    "Deeplabv3_train_losses, Deeplabv3_val_losses, Deeplabv3_time = get_info_from_path('/content/drive/MyDrive/Aorta_Segmentation/Training_info/deeplabv3_losses.pt')\n",
    "Deeplabv3_pretrained_train_losses, Deeplabv3_pretrained_val_losses, Deeplabv3_pretrained_time = get_info_from_path('/content/drive/MyDrive/Aorta_Segmentation/Training_infodeeplabv3_pretrained_losses.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(rows, cols, idx, title, train_losses, val_losses):\n",
    "    plt.subplot(rows, cols, idx)\n",
    "    plt.plot(train_losses, \"r-\", label=\"Training Loss\")\n",
    "    plt.plot(val_losses, \"b-\", label=\"Validation Loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\",)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    if idx == 1:\n",
    "        plt.legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db479d2",
   "metadata": {
    "id": "6db479d2"
   },
   "outputs": [],
   "source": [
    "data_tuples = [\n",
    "    (\"UNet - Losses\", Unet_train_losses, Unet_val_losses),\n",
    "    (\"FCN Losses\", FCN_train_losses, FCN_val_losses),\n",
    "    (\"FCN Pretrained Losses\", FCN_pretrained_train_losses, FCN_pretrained_val_losses),\n",
    "    (\"DLv3 Losses\", Deeplabv3_train_losses, Deeplabv3_val_losses),\n",
    "    (\"DLv3 Pretrained Losses\", Deeplabv3_pretrained_train_losses, Deeplabv3_pretrained_val_losses)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(15, 10), dpi=300)\n",
    "for idx, tuple in enumerate(data_tuples):\n",
    "    plot_losses(2, 3, idx+1, tuple[0], tuple[1], tuple[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e3971",
   "metadata": {
    "id": "074e3971"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Aorta_Segmentation/Data_names/data_names_dict.txt\", \"w\") as file:\n",
    "    data_names_dict = json.load(file)\n",
    "\n",
    "test_data_names = data_names_dict[\"test\"]\n",
    "Testing_dataset = Dataset(test_data_names)\n",
    "Testing_dataset.Preprocess_Data()\n",
    "testing_loader = tc.utils.data.DataLoader(Testing_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ad6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel:\n",
    "    def __init__(self, model, model_name):\n",
    "        self.model = model\n",
    "        self.model_name = model_name\n",
    "        self.predictions = []\n",
    "        self.mask_lst = []\n",
    "        self.threshold = 0.5\n",
    "        self.device = tc.device(\"cuda\" if tc.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        #Metrics\n",
    "        self.dice_func = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=True)\n",
    "        self.hd95_func = HausdorffDistanceMetric(include_background=True, reduction=\"mean\", get_not_nans=True)\n",
    "        self.dice_score = []\n",
    "        self.hd95 = [] \n",
    "    \n",
    "    def pred_loop(self, testing_loader):\n",
    "        for images, masks in testing_loader:\n",
    "            images = images.to(self.device)\n",
    "            masks = masks.to(self.device)\n",
    "            output = self.model(images.unsqueeze(1))\n",
    "            if isinstance(output, dict):\n",
    "                output = output[\"out\"]\n",
    "            output = tc.nn.Sigmoid()(output)\n",
    "            output = (output > self.threshold).int()\n",
    "            self.predictions.append(output.cpu())\n",
    "            self.mask_lst.append(masks.unsqueeze(1).cpu())\n",
    "        self.predictions = tc.cat(self.predictions, dim=0)\n",
    "        self.mask_lst = tc.cat(self.mask_lst, dim=0)\n",
    "        self.calculate_dice_score()\n",
    "        self.calculate_hd95()\n",
    "    \n",
    "    def test_model(self):\n",
    "        self.model.eval()\n",
    "        with tc.no_grad():\n",
    "            self.pred_loop()\n",
    "    \n",
    "    def calculate_dice_score(self):\n",
    "        dice_score = self.dice_func(self.predictions, self.mask_lst)\n",
    "        dice_score = dice_score[~dice_score.isnan()]\n",
    "        dice_score = dice_score[~dice_score.isinf()]\n",
    "        self.dice_score = dice_score\n",
    "    \n",
    "    def calculate_hd95(self):\n",
    "        hd95_score = self.hd95_func(self.predictions, self.mask_lst)\n",
    "        hd95_score = hd95_score[~hd95_score.isnan()]\n",
    "        hd95_score = hd95_score[~hd95_score.isinf()]\n",
    "        self.hd95 = hd95_score\n",
    "    \n",
    "    def get_predictions(self):\n",
    "        return self.predictions\n",
    "    \n",
    "    def get_masks(self):\n",
    "        return self.mask_lst\n",
    "\n",
    "    def print_model_metrics(self):\n",
    "        print(f\"------- {self.model_name} metrics -------\")\n",
    "        print(f\"Average Dice score: {self.dice_score.mean():.4f}\")\n",
    "        print(f\"Minimum Dice score: {self.dice_score.min():.4f}\")\n",
    "        print(f\"Maximum Dice score: {self.dice_score.max():.4f}\")\n",
    "        print(f\"Std Dice score: {self.dice_score.std():.4f}\")\n",
    "        print(\"----\")\n",
    "        print(f\"Average HD95 score: {self.hd95.mean():.4f}\")\n",
    "        print(f\"Minimum HD95 score: {self.hd95.min():.4f}\")\n",
    "        print(f\"Maximum HD95 score: {self.hd95.max():.4f}\")\n",
    "        print(f\"Std HD95 score: {self.hd95.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23007598",
   "metadata": {
    "id": "23007598"
   },
   "outputs": [],
   "source": [
    "model_Unet = UNet(\n",
    "        spatial_dims = 2,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=[16, 32, 64, 128, 256],\n",
    "        strides=(2, 2, 2, 2),\n",
    "        dropout=0.16454162080022391\n",
    "    )\n",
    "\n",
    "model_FCN = models.segmentation.fcn_resnet50(weights=None, num_classes=1)\n",
    "model_FCN.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model_FCN_pretrained = models.segmentation.fcn_resnet50(weights=None, num_classes=1) #there is no point to load weights if we load state dict \n",
    "model_FCN_pretrained.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model_deeplabv3 = models.segmentation.deeplabv3_mobilenet_v3_large(weights=None, num_classes=1)\n",
    "model_deeplabv3.backbone._modules[\"0\"]._modules[\"0\"] = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "\n",
    "model_deeplabv3_pretrained = models.segmentation.deeplabv3_mobilenet_v3_large(weights=None, num_classes=1)\n",
    "model_deeplabv3_pretrained.backbone._modules[\"0\"]._modules[\"0\"] = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "\n",
    "model_Unet.load_state_dict(tc.load('/content/drive/MyDrive/Aorta_Segmentation/Models/UNet_trained.pth'))\n",
    "model_FCN.load_state_dict(tc.load('/content/drive/MyDrive/Aorta_Segmentation/Models/FCN_trained.pth'))\n",
    "model_FCN_pretrained.load_state_dict(tc.load('/content/drive/MyDrive/Aorta_Segmentation/Models/FCN_pretrained_trained.pth'))\n",
    "model_deeplabv3.load_state_dict(tc.load('/content/drive/MyDrive/Aorta_Segmentation/Models/deeplabv3_trained.pth'))\n",
    "model_deeplabv3_pretrained.load_state_dict(tc.load('/content/drive/MyDrive/Aorta_Segmentation/Models/deeplabv3_pretrained_trained.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"Unet\": TestModel(model_Unet, \"UNet\"),\n",
    "    \"FCN\": TestModel(model_FCN, \"FCN\"),\n",
    "    \"FCN pretrained\": TestModel(model_FCN_pretrained, \"FCN pretrained\"),\n",
    "    \"DLv3\": TestModel(model_deeplabv3, \"Deeplabv3\"),\n",
    "    \"DLv3 pretrained\": TestModel(model_deeplabv3_pretrained, \"Deeplabv3 pretrained\")\n",
    "}\n",
    "\n",
    "for key in models_dict:\n",
    "    models_dict[key].test_model()\n",
    "    models_dict[key].print_model_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9d970",
   "metadata": {
    "id": "96a9d970"
   },
   "outputs": [],
   "source": [
    "model_names = []\n",
    "dices_lst = []\n",
    "hd95_lst = []\n",
    "\n",
    "for key in models_dict:\n",
    "    model_names.append(models_dict[key].model_name)\n",
    "    dices_lst.apeend(models_dict[key].dice_score.mean().item())\n",
    "    hd95_lst.append(models_dict[key].hd95.mean().item())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = sns.barplot(x=model_names, y=dices_lst, palette=sns.color_palette(palette='cool'))\n",
    "for i, value in enumerate(dices_lst):\n",
    "    ax.text(i, value + 0.02, f'{value:.2f}', ha='center', va='bottom', fontsize=12)\n",
    "plt.title(\"Dice Comparison\")\n",
    "plt.ylabel(\"Average Dice score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b700a",
   "metadata": {
    "id": "3f1b700a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax_2 = sns.barplot(x=model_names, y=hd95_lst, palette=sns.color_palette(palette='cool'))\n",
    "for i, value in enumerate(hd95_lst):\n",
    "    ax_2.text(i, value + 0.02, f'{value:.2f}', ha='center', va='bottom', fontsize=12)\n",
    "plt.title(\"HD95 Comparison\")\n",
    "plt.ylabel(\"Average HD95 score\")\n",
    "plt.ylim(0, 23)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
